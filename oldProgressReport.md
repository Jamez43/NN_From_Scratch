# Completed Topics
- Dot product
- Activation Functions
 - reLU
 - softmax

nn.py showcases everything put together

# Troubling Topics/Questions
There was a section showcasing how you can manually tune a nn ,(1,8,8,1), to match a sine wave, and I was having a little trouble understanding how you are able to tell each function when to stop. I kind of get it, but I kinda just skipped over it.


# Current Topic
## Loss Function

# Remaining Chapters
- Introducing Optimization
- Derivitives
- Gradients, Partial Derivitives, and the Chain Rule
- Backpropogation
- Optimizers
- Testing data
- Validation Data
- Training Data
- L1 and L2 Regulation
- Dropout
- Binary Logistic Regression
- Regression
- Model Object
- A Real Dataset
- Model Evaluation
- Saving and Loading Model Information
- Model Predicting_Inference